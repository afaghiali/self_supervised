{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpefXMSeHBjp3MEhii98ib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afaghiali/self_supervised/blob/master/runthis_semisupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj0NM7QpIxqR",
        "outputId": "7ca4ecb9-de46-40d8-97a7-4c9a41f88f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'self_supervised' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/afaghiali/self_supervised\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6SC5p4jJor1",
        "outputId": "ccd84af9-64d3-4ca0-93c7-6c63da98f518"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir data"
      ],
      "metadata": {
        "id": "F3UbQZF1LG7N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/fundus.tar /content/data\n",
        "!cp /content/drive/MyDrive/random_list.txt /content/data\n",
        "!cp /content/drive/MyDrive/FFA_syn_AMD.rar /content/data"
      ],
      "metadata": {
        "id": "pjjMltipLsG6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEfWWkLeIrUe",
        "outputId": "a7cbd3e0-a878-4cfb-8fe3-98dd1ea3b675"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir fundus"
      ],
      "metadata": {
        "id": "ARjSpWbXMVIK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unrar\n",
        "!unrar x /content/data/FFA_syn_AMD.rar\n",
        "!tar -xvf /content/data/fundus.tar -C /content/data/fundus"
      ],
      "metadata": {
        "id": "hMkjbThNHtZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/self_supervised"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP7gD21gtVqI",
        "outputId": "85567f92-2e03-459d-f595-f33ca8715a2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/self_supervised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max=5\n",
        "# for i in `seq 0 $max`\n",
        "# for i in range(0,5):\n",
        "# do\n",
        "NUM=1\n",
        "NUM2=2\n",
        "CUDA_VISIBLE_DEVICES='0' \n",
        "!python main.py  /content/data/ --arch resnet18 -j 32  --nce-t 0.07 --lr 1e-4 --nce-m 0.5 --low-dim 128 -b 17 --epochs 500 --result exp/fundus_amd/AMD_ours --seedstart 1 --seed 0 --multiaug --synthesis\n",
        "# done"
      ],
      "metadata": {
        "id": "w-eWsXEyDQ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768ec7d2-7813-41db-8a60-a688edde89dc"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of learnable params 11.242176  M\n",
            "train p:  73 246\n",
            "test p:  14 65\n",
            "Train images AMD  319 P:  73 N:  246\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "train p:  73 246\n",
            "test p:  14 65\n",
            "Test images AMD  79 P:  14 N:  65\n",
            "running synthesis\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: [0][0/18]\tTime 15.362 (15.362)\tData 1.404 (1.404)\tLoss 10.8700 (10.8700)\t\n",
            "Epoch: [0][10/18]\tTime 10.899 (11.603)\tData 0.006 (0.134)\tLoss 10.6372 (10.5939)\t\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 388, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 269, in main\n",
            "    loss = train(train_loader, model, lemniscate, criterion, optimizer, epoch, writer)\n",
            "  File \"main.py\", line 342, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 396, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising an empty repository\n",
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDUIciRixhK3",
        "outputId": "2e16849e-f1ec-4fdf-a5f6-a7ae2c051e9f"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/self_supervised/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your email to the global config-file\n",
        "!git config --global user.email 'afaghiali@yahoo.com'"
      ],
      "metadata": {
        "id": "rpA0SIMgxl8p"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your username to the global config-file\n",
        "# !git config --global user.name 'afaghiali'\n",
        "!git config --global user.name \"afaghiali\"\n"
      ],
      "metadata": {
        "id": "A0F1rrs-x0Ex"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# . is to add all the files. You can selectively select the files you can add too\n",
        "# by mentioning the file names\n",
        "!git add ."
      ],
      "metadata": {
        "id": "T6TJLa-xx7bp"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commiting the added files and writing a commit message along with it\n",
        "!git commit -m \"self_supervised\""
      ],
      "metadata": {
        "id": "E9p4NQjKyLia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41d5281-13ad-4bce-ee2a-9312ba5d7ce1"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master 56dd2ec] self_supervised\n",
            " 16 files changed, 264 insertions(+), 31 deletions(-)\n",
            " rewrite __pycache__/test.cpython-37.pyc (77%)\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/code_file/untitled\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/code_file/untitled1\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/result.txt\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/resulta.txt\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/resultaa.txt\n",
            " create mode 100644 exp/fundus_amd/AMD_ours1/untitled\n",
            " create mode 100644 runs/AMD_ours1/events.out.tfevents.1665959474.c69aaa7d9e10.7170.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new personal access token from https://github.com/settings/tokens\n",
        "!git remote set-url origin https://afaghiali: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@github.com/afaghiali/self_supervised.git\n"
      ],
      "metadata": {
        "id": "pX2s0ASKJrSJ"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -f origin master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwRkJaOEZ7t_",
        "outputId": "5c026cd7-38d1-43bb-d0f2-0ada41a4ffc9"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 22, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:   5% (1/17)   \rCompressing objects:  11% (2/17)   \rCompressing objects:  17% (3/17)   \rCompressing objects:  23% (4/17)   \rCompressing objects:  29% (5/17)   \rCompressing objects:  35% (6/17)   \rCompressing objects:  41% (7/17)   \rCompressing objects:  47% (8/17)   \rCompressing objects:  52% (9/17)   \rCompressing objects:  58% (10/17)   \rCompressing objects:  64% (11/17)   \rCompressing objects:  70% (12/17)   \rCompressing objects:  76% (13/17)   \rCompressing objects:  82% (14/17)   \rCompressing objects:  88% (15/17)   \rCompressing objects:  94% (16/17)   \rCompressing objects: 100% (17/17)   \rCompressing objects: 100% (17/17), done.\n",
            "Writing objects:   4% (1/22)   \rWriting objects:   9% (2/22)   \rWriting objects:  13% (3/22)   \rWriting objects:  18% (4/22)   \rWriting objects:  22% (5/22)   \rWriting objects:  27% (6/22)   \rWriting objects:  31% (7/22)   \rWriting objects:  36% (8/22)   \rWriting objects:  40% (9/22)   \rWriting objects:  45% (10/22)   \rWriting objects:  50% (11/22)   \rWriting objects:  54% (12/22)   \rWriting objects:  59% (13/22)   \rWriting objects:  63% (14/22)   \rWriting objects:  68% (15/22)   \rWriting objects:  72% (16/22)   \rWriting objects:  77% (17/22)   \rWriting objects:  81% (18/22)   \rWriting objects:  86% (19/22)   \rWriting objects:  90% (20/22)   \rWriting objects:  95% (21/22)   \rWriting objects: 100% (22/22)   \rWriting objects: 100% (22/22), 8.02 KiB | 8.02 MiB/s, done.\n",
            "Total 22 (delta 9), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/9)\u001b[K\rremote: Resolving deltas:  11% (1/9)\u001b[K\rremote: Resolving deltas:  22% (2/9)\u001b[K\rremote: Resolving deltas:  33% (3/9)\u001b[K\rremote: Resolving deltas:  44% (4/9)\u001b[K\rremote: Resolving deltas:  55% (5/9)\u001b[K\rremote: Resolving deltas:  66% (6/9)\u001b[K\rremote: Resolving deltas:  77% (7/9)\u001b[K\rremote: Resolving deltas:  88% (8/9)\u001b[K\rremote: Resolving deltas: 100% (9/9)\u001b[K\rremote: Resolving deltas: 100% (9/9), completed with 8 local objects.\u001b[K\n",
            "To https://github.com/afaghiali/self_supervised.git\n",
            "   14da454..56dd2ec  master -> master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/data\n",
        "!mkdir savedmodels"
      ],
      "metadata": {
        "id": "AfCTekhEGNwJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/savedmodels.tar.gz\" -C \"/content/data/savedmodels\"     #[run this cell to extract tar.gz files]"
      ],
      "metadata": {
        "id": "fLteKnE2Fm5t",
        "outputId": "faa655ce-9211-4a77-92a4-19adb74b2cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "savedmodels/\n",
            "savedmodels/fold3-epoch-2000.pth.tar\n",
            "savedmodels/fold4-epoch-2000.pth.tar\n",
            "savedmodels/fold2-epoch-2000.pth.tar\n",
            "savedmodels/fold0-epoch-2000.pth.tar\n",
            "savedmodels/fold1-epoch-2000.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ..\n"
      ],
      "metadata": {
        "id": "VIAAm3kOIwsg",
        "outputId": "fb86b739-f531-40b5-afc0-ad06992de1ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/self_supervised"
      ],
      "metadata": {
        "id": "OCmPDtM8KmNx",
        "outputId": "6dda8353-d97b-4a6f-9c9a-6fe065f01103",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/self_supervised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max=4\n",
        "# for i in `seq 0 $max`\n",
        "# do\n",
        "  #  NUM=\"${var}$i\"\n",
        "NUM=1\n",
        "!python main.py  /content/data/ --arch resnet18 -j 32  --nce-t 0.07 --lr 1e-4 --nce-m 0.5 --low-dim 128 -b 75  --result exp/fundus_amd/AMD_ours --seedstart $NUM  --multiaug   --synthesis --evaluate --resume /content/data/savedmodels/savedmodels/fold$NUM-epoch-2000.pth.tar\n",
        "# done\n",
        "# python read_result.py"
      ],
      "metadata": {
        "id": "0SQR4X4cG19r",
        "outputId": "48062776-9404-4fd5-fb60-3da7b51a5a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of learnable params 11.242176  M\n",
            "train p:  73 246\n",
            "test p:  14 65\n",
            "Train images AMD  319 P:  73 N:  246\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "train p:  73 246\n",
            "test p:  14 65\n",
            "Test images AMD  79 P:  14 N:  65\n",
            "running synthesis\n",
            "=> loading checkpoint '/content/data/savedmodels/savedmodels/fold1-epoch-2000.pth.tar'\n",
            "after checkpoint\n",
            "<class 'collections.OrderedDict'>\n",
            "=> loaded checkpoint '/content/data/savedmodels/savedmodels/fold1-epoch-2000.pth.tar' (epoch 2000)\n",
            "auc 0.7626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max=5\n",
        "for i in range(0,max):\n",
        "  \n",
        "  NUM=\"${var}$i\"\n",
        "  !python main.py  /content/data/ --arch resnet18 -j 32  --nce-t 0.07 --lr 1e-4 --nce-m 0.5 --low-dim 128 -b 75  --result exp/fundus_amd/AMD_ours --seedstart $i  --multiaug   --synthesis --evaluate --resume /content/data/savedmodels/savedmodels/fold$i-epoch-2000.pth.tar\n",
        "  "
      ],
      "metadata": {
        "id": "oq37g1oct32w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python read_result.py"
      ],
      "metadata": {
        "id": "_C0vYwxHxBx_",
        "outputId": "a2cd0bb7-67ae-49f8-8cdf-c5cba6bc1412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-fold result: \n",
            "AUC 74.58\n",
            "acc 86.58\n",
            "precision 83.2\n",
            "recall 74.58\n",
            "f1score 77.33\n"
          ]
        }
      ]
    }
  ]
}